---
title: WIP『ビッグデータを支える技術』を読んだ
date: 2020-01-18
tags: database, book
---

[ビッグデータを支える技術―刻々とデータが脈打つ自動化の世界](https://www.amazon.co.jp/dp/4774192252)

仕事で広告配信のログを扱っているので、周辺ノウハウをつけるために読んだ。
仕事場で実物を見ていたので読んだ内容を体験と照合することでかなり楽しく読めた。

以下では心に響いた

## アーキテクチャ

データ処理の基盤は概ね下記に分割できる。

1. データソース
    - 処理対象のデータ
2. データウェアハウス
    - 長期保存用の大規模データ
3. データマート
    - 分析用に加工された中規模データ
4. 可視化ツール
    - 分析用のユーザインタフェース

## データマート

BIツールなどでの集計速度を保つためにデータマートの層は必須となる。
これは通常バッチ処理でデータが構築されるので、必然的にバッチ処理のワークフローを管理する仕組みが必要になる。

### 2.2. 列指向ストレージ

データ量が増えてメモリに乗り切らなくなっても高速に集計の応答を得るためにはまずシステム構成を下記のように構成する。

1. データレイク→データマート
    - データ集約
2. データマート→可視化ツール
    - クロス集計

データ処理の遅延「レイテンシ」が小さいデータマートを作るときには2つの選択肢がある。

データをすべてのメモリに載せる。

その規模のデータだと RDB が適している。しかしメモリが不足すると急激に性能が落ちる特徴がある。

数億レコードを扱うならディスク I/O を前提としてそれを効率化すること別の選択肢を検討する。

この高速化のために「圧縮」と「分散」を活用する。データを圧縮して小さく保つことで複数のディスクへと分散し読み込み時間を小さくする。さらにマルチコアを使って I/O を並列化する。こうしたアーキテクチャを MPP と呼ぶ。

MPP は集計に最適化されている。実装としては Redshift や BigQuery などがある。

列指向データベースでは列単位でのデータ圧縮を行う。
データ分析では一部の列だけが集計対象になる傾向があるので、必要ない列を読み込まなくて済むような保存方法になっている。
さらに同じ列には似たようなデータが並ぶことを活用して高い圧縮効率を実現している。

行指向データベースでは一つあたりのクエリはたいてい短いクエリが何度も呼び出される時に効率的になるように設計さ
れている。したがってクエリごとの分散処理が行われる。
それに対して MPP データベースでは一回のクエリが長いことが大抵であるためクエリ自体を分散処理する。クエリをタスクに分解してそれらを並列実行する。

### 2.4. データマートの基本構造

中心となるのは OLAP と呼ばれる仕組み。
データ収集を効率化するアプローチ。
OLAP は多次元モデルを MDX などのクエリ言語で集計する。この多次元データを OLAP キューブと呼び、これをクロス集計するのが OLAP である。
BI ツールはもともと OLAP を使ってデータ集計するものだった。データマートも以前は OLAP キューブとして作成されていた。

近年は MPP やインメモリデータベースによって OLAP キューブを作らなくても良くなってきた。MPP では多次元モデルの代わりに非正規化テーブルを用意する。
BI ツールで可視化に適したデータを作るとは、すなわちデータマートにおいて非正規化テーブルを作ることを意味する。

#### 非正規化テーブルとは

行動や事実の記録をファクトテーブルという。一方でマスタデータをディメンジョンテーブルという。
データマートではファクトテーブルを中心に複数のディメンジョンテーブルが結合されたスタースキーマが好ましいとされる。

RDB ではマスタデータが正規化されて複数のテーブルに分割されるが、データマートではこのディメンジョンテーブルをできるだけ非正規化する。

#### スタースキーマの利点

これによりテーブル結合がシンプルになりBIツールからのSQL生成がしやすくなる。
またファクトテーブルはデータ量が肥大化しがちなのでカラムをIDのようなキーだけ格納してラベルをディメンジョンテーブルに追い出すことでストレージの節約ができる。

列指向データベースの登場によりカラム数の増加が起きても性能影響が少なくなってきた。カラムのデータ圧縮も効くので尚更。
従って一つの巨大なファクトテーブルがありさえすればよくなってきた。多くの列指向データベースではもはやスタースキーマも不要になってきている。

### 3.3 データマートの構築

ファクトテーブル

作成には追記と置換を用いる。
置換はテーブルの作り直しを指す。（コスト高そう）

ファクトテーブルのデータ欠損、重複、作り直しを容易にするためにパーティション分割をおこなう。通常、データの重複を避けるために毎回置換するように操作することで冪等性を保つ。このようなテーブルをデータウェアハウスに溜めておいて必要なデータだけをデータマートにインポートする。

データマートの場合はパーティション置換よりもテーブルの作り直しの方が多い。例えば過去1ヶ月のデータを毎日取り出して置き換える。

ファクトテーブル全体を置換するメリット

データの整合が保てる。テーブルの作り直しはクエリ1つ。（ほんまか？）スキーマの変更にも柔軟に対応。

デメリット

書き込みの処理時間。並列書き込みでもテーブルの作り直しに時間がかかる場合はパーティションを検討する。目安は一時間以内にファクトテーブルを作れるなら毎回置換でも充分。

サマリテーブル

ファクトテーブルから集計したデータを日次などで保存しておくテーブル。サイズはデータのカーディナリティに大きく左右される。
（これは何がメリットなんだろう）

スナップショットテーブル

時間の経過とともにテーブルをまるごと保存する。一種のファクトテーブル。
ディメンジョンテーブルが日々変化する中で過去のディメンジョンを使って集計する際に役に立つ。

履歴テーブル

全データのスナップショットをとるのではなく差分だけを記録するテーブル。ただし復元に複雑なクエリが必要になるので、よっぽどスナップショットのサイズが問題になるのでない限り使う機会はない。

データ集約の基本形

1. サブクエリでファクトテーブルの件数を絞り込む
2. ディメンジョンテーブルと結合する
3. GROUP BY で集約する

#### 多次元モデル

BIツールにおける集計を表現するモデル。
クロス集計の集計軸をディメンジョンと呼び、集計される数値と集計方法をメジャーと呼ぶ。
2つの列を選んでクロス集計する時、その集計表の次数は2次元である。

## データインジェスチョン

- バルク型
- ストリーミング型

時系列データを一つ一つファイルとして落とすと上記の問題にあたるためデータをまとめて一つのファイルに保存する方法が取られる。このように効率の良いストレージを作ることをデータインジェスションと呼ぶ。

バルク

生データから分散ストレージへの転送を担うノードをETLサーバと呼ぶ。ETLサーバはデータを抽出して保存し、次に転送タスクを実行する。（Embulk などがそれだな）
データ量に応じて転送の頻度を変える必要がある。ワークフロー管理ツールをおくとこのタスク実行を管理しやすくなる。

転送の信頼性が大事ならバルクを勧める。やり直しがきく。
（広告配信のログなどは信頼性第一なのでバルクが適していそう）

ストリーミング

まだどこにも保存されていないデータはまず保存できるところに転送する必要があるのでストリーミングが必要になる。
（あー、バルクと比較する、というよりはストリーミングはバルクのフロントエンドなんだな）

高頻度に小さなデータを保存する性質からNoSQLストレージが適していることが多い。またはメッセージキューやメッセージブローカなどの中継システ厶を置くこともある。
バッファ機能を持つメッセージ配送のひとつにfluentdがある。

モバイルだとネットワークが不安定なので、SDK内部で蓄積しておんらいんになったらまとめてsyncする方式がとられる。

### 4.2. トレードオフ

書き込み頻度が増えるにつれて性能は悪化しやすい。クライアントは失敗すれば再送を試みるので更に負荷は増えやすい。

これに耐えるためには書き込み性能が高くスケールアウト可能なストレージが必要だがそう簡単には見つからないもの。なのでメッセージングアーキテクチャには配送メッセージを一時保存してバッファリングを行うブローカーがいる。（つまりクライアントからフロントエンド、そこからストレージに直書きせずに、間にブローカーをかませる）

プッシュしたメッセージをブローカに書き込み、ETLがプルしてストレージにロードするというパターンが考えられる。

信頼性

- at most once
- at least once
- exactly once

exactly once

到達性を保証するにはコーディネーターなどが必要。しかしそれが性能のネックになることもある。

at least once

重複排除する仕組みを別途導入できるなら at least once は許容できるはず。多くのメッセージングシステムはこれ。しかしこの操作はとても高コスト。

メッセージに書き込み先ファイルのオフセットを入れておく。
再送されてもファイルの同じオフセットに書き込まれるだけなので冪等。

ユニークIDをつけることで重複排除。最近受け取ったIDを記録しておいて重複排除。その記録が期限切れで破棄された後にきた重複は受け入れる。

重複排除は基本的にエンドツーエンドの仕組みを作らなければ実現不可能。
配送経路に at most once と at least once が混ざれば両方に対応する必要ができてコストは増すばかり。

代表的な重複排除

### 4.3. 時系列データの最適化

メッセージが届いた時間と処理される時間の違い。

スマホだとオンラインになるまで時間が開くことがあるため、メッセージの生成から到着に数日遅延があることもある。

生成をイベント時間
到着をプロセス時間

通常はイベント時間を分析したいので、数日さかのぼって集計することになる。
一方データを保存するファイルはプロセス時間単位で作ることが多い。
 つまり1/1のメッセージを全て検索するためにはその日のプロセス時間のファイルだけではなく、送れて届いたプロセス時間のファイルも読み込む必要がある。これは膨大なファイルスキャンを招くことになり効率が悪い。

時系列インデックスの導入

Cassandra などの時系列インデックスを持つデータベースではイベント時間をベースに並べ替えをしておくことで検索を効率化できる。これにより短い範囲でのリアルタイム集計は素早くできるようになる。長期間にわたる検索はそれでも向かないので集計効率の高い列指向データベースを別途使ったほうが良い。

述語プッシュダウン

定期的に新しく届いたCSVをイベント時間で並び替えて列指向ストレージに保存すると考える。
（何が嬉しいのかちゃんとメモされていない）


