---
title = "SMLの関数適用を構文解析する時の問題"
date = 2017-09-30
aliases = ["/posts/note/2017-09-30_19-30-43.html"]
[taxonomies]
tags = ["standardml","sml","haskell","compiler"]
---

まだ[構文解析](http://d.hatena.ne.jp/keyword/%B9%BD%CA%B8%B2%F2%C0%CF)器で苦労している。 今回も詰まっているのは構文のconflict。

## 問題

これが関数適用

    app : exp exp

これが[二項演算子](http://d.hatena.ne.jp/keyword/%C6%F3%B9%E0%B1%E9%BB%BB%BB%D2)適用

    infixapp : exp vid exp

この時に入力を

    x y z

とすると２つの解釈ができてしまうことになる。

    ((x y) z)

とするネストした関数適用なのか

    x y z

とする[二項演算子](http://d.hatena.ne.jp/keyword/%C6%F3%B9%E0%B1%E9%BB%BB%BB%D2)の適用なのかParserが判断つけられない。

前者ならreduceするが後者ならshiftする。 なのでこれはshift/reduce conflictが起きていると言える。 happyはデフォルトでshiftするので[二項演算子](http://d.hatena.ne.jp/keyword/%C6%F3%B9%E0%B1%E9%BB%BB%BB%D2)として解釈される。

これを解消したい。

## 解決

sml-njやmltonのgrmファイルの定義を覗いたところ

    FlatAppExp : exp list

のようなデータコンストラクタを使ってとりあえずシンボルのリストとしていったん読み込んでしまうらしい。 なぜ関数適用と[二項演算子](http://d.hatena.ne.jp/keyword/%C6%F3%B9%E0%B1%E9%BB%BB%BB%D2)適用は全然違う構造にも関わらず峻別せずに扱うのだろうと疑問に思った。

## なぜだろう

SMLではfixityを自分で定義して[二項演算子](http://d.hatena.ne.jp/keyword/%C6%F3%B9%E0%B1%E9%BB%BB%BB%D2)を作れる。

左結合か右結合かをどこかのテーブルに保存しておくことになる。(おそらくEnv的なもの？まだそのあたり解らない) こういう動的にassociativityが定義される[二項演算子](http://d.hatena.ne.jp/keyword/%C6%F3%B9%E0%B1%E9%BB%BB%BB%D2)はパーサジェネレータでは扱えないっぽい。

なので一度解析しきってから、後でsanityチェックして弾くっぽい。

解析の途中でこのfixityのテーブルを更新しながら進めば別に解析の完了を待たなくてもいいじゃんとも思った。 けれど、それだとfixityの定義が必ず[演算子](http://d.hatena.ne.jp/keyword/%B1%E9%BB%BB%BB%D2)の使用よりも前に定義済みである必要がある。 それは不便だろう。

ということで[Flat](http://d.hatena.ne.jp/keyword/Flat)なんたらという構造を導入してなんとか解決はできた。

追記

[http://dev.stephendiehl.com/fun/008\_extended\_parser.html](http://dev.stephendiehl.com/fun/008_extended_parser.html)

ここを見るとinfix operatorを動的に定義していく方法が提示されているが、やはりparsecだな。[ghc](http://d.hatena.ne.jp/keyword/ghc)はどうやっているのか見てみる必要ありかな。。。

## 納得いってない

悪手かなと思うのは、こうした[構文解析](http://d.hatena.ne.jp/keyword/%B9%BD%CA%B8%B2%F2%C0%CF)上の問題のために抽象的なデータ構造にコンストラクタを追加しなければならないという点。 せっかくきれいにsyntax objectを定義できたのにノイズが入ってしまうみたいでイマイチだなと思う。

これだと

    1 + 2 + 3

みたいな入力は

    ["1", "+", "2", "+", "3"]

のようにreduceされる。

parsecならこれをexpression builder的な[API](http://d.hatena.ne.jp/keyword/API)でうまく[木構造](http://d.hatena.ne.jp/keyword/%CC%DA%B9%BD%C2%A4)に変換できるのだが。。。 まあ、部分的にparsec使うのはありかもしれない。

## これから

あとはモジュール系の[構文解析](http://d.hatena.ne.jp/keyword/%B9%BD%CA%B8%B2%F2%C0%CF)が作れればとりあえず[構文解析](http://d.hatena.ne.jp/keyword/%B9%BD%CA%B8%B2%F2%C0%CF)のステージは終わりだろう。 と、言いたいところだがshift/reduceやreduce/reduceのconflictがわんさか残っている。

どうしよう。。。問題ないならこのまま進めてしまいたい。 正直conflictの解消法は未だにわかってない。

あとまだわかってないこと。

- [構文解析](http://d.hatena.ne.jp/keyword/%B9%BD%CA%B8%B2%F2%C0%CF)終わった後のsyntax objectに位置情報を顕に保存していないけれどtype checkエラーの時に位置情報含めてレポートできるのか？
- そもそもエラーレポートがすごくわかりにくい。後で苦労するので早めにverboseなレポート出せるようにしたい。

やりながら良かったと思うこと。

- [haskell](http://d.hatena.ne.jp/keyword/haskell)のhappy使ってるけどmlyaccや[yacc](http://d.hatena.ne.jp/keyword/yacc)ととても似ているため他のツールチェイン使った時もこのノウハウは活きるだろう
- テストはこまめに書いているので「ここまでは動く」という証左が得られる安心感はやっぱり良い。[プログラマ](http://d.hatena.ne.jp/keyword/%A5%D7%A5%ED%A5%B0%A5%E9%A5%DE)としてこの感覚は大事にしたい。

## その他近況メモ(ぼやき)

### [カーネル](http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB)

詳解[Linux](http://d.hatena.ne.jp/keyword/Linux)[カーネル](http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB)読んでる。 メモリアドレッシングからいきなりハードル高い。

特にページングテーブルの初期化のところとか全然解らない。

### [Clojure](http://d.hatena.ne.jp/keyword/Clojure)

[Scala](http://d.hatena.ne.jp/keyword/Scala)勉強しなきゃ、からマッハで脱線して[Clojure](http://d.hatena.ne.jp/keyword/Clojure)の情報ばかり漁っている。

どっかの記事で「[Clojure](http://d.hatena.ne.jp/keyword/Clojure)は大規模プロジェクトになるとメンテナンスが難しくなってきてスケールしない」みたいなこと言ってた。 そうだろうなと思う。[リファクタリング](http://d.hatena.ne.jp/keyword/%A5%EA%A5%D5%A5%A1%A5%AF%A5%BF%A5%EA%A5%F3%A5%B0)はそれほど気軽にできないだろう。

specが出てきてチェック機構は揃ってきているけれど、 それでもやはり「実行しないと結果が解らない」という制約は残る。

REPLで探索しながら直すべきところは見つけられるよ、という意見もあるかもしれないけれど[リファクタリング](http://d.hatena.ne.jp/keyword/%A5%EA%A5%D5%A5%A1%A5%AF%A5%BF%A5%EA%A5%F3%A5%B0)の過程で影響のあるところ全部を検査する仕組みはやっぱり無いではなかろうか。 というか[リファクタリング](http://d.hatena.ne.jp/keyword/%A5%EA%A5%D5%A5%A1%A5%AF%A5%BF%A5%EA%A5%F3%A5%B0)して壊れたところを[機械的](http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%C5%AA)に見つける手段が無い、と言うべきか。

[Clojure](http://d.hatena.ne.jp/keyword/Clojure)もそうだけど、[Ruby](http://d.hatena.ne.jp/keyword/Ruby)や[Python](http://d.hatena.ne.jp/keyword/Python)やJS使っている人たちどうしているのだろう。素朴に疑問。

とかぐだぐだ言いながらもなんか[Clojure](http://d.hatena.ne.jp/keyword/Clojure)好きなので勉強を続けてしまう。

